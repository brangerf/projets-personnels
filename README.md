# projets-personnels

*A propos de chat_and_rag :*

Ce projet est un module de développement séparé, destiné à une future implémentation au sein de mon prototype d'application complet. Il se présente sous la forme d'une application de bureau qui permet de chatter avec des modèles de langage locaux via Ollama.
La fonctionnalité principale est de pouvoir poser des questions sur un document personnel. Pour la recherche sémantique, l'approche est un peu plus élaborée. Plutôt que de chercher les mots exacts de la question, j'utilise d'abord le modèle de langage pour extraire les concepts clés et leurs variations. Ensuite, le programme recherche ces termes dans le document et identifie les zones où ils sont les plus pertinents et concentrés. Ces passages sont évalués selon plusieurs critères, notamment la diversité des concepts qu'ils contiennent et la proximité des termes entre eux. Pour éviter de présenter des informations redondantes, un filtre de similarité Jaccard est appliqué pour ne retenir que les extraits les plus uniques, qui formeront le contexte final de la réponse.
L'interface de ce module a été volontairement épurée pour se concentrer exclusivement sur cette mécanique. Elle offre les contrôles essentiels : le chargement d'un document, le dialogue, et la possibilité de modifier les paramètres du modèle ou son prompt système. Ce composant a été conçu comme un banc d'essai pour valider et affiner la technologie de recherche sémantique avant de la fusionner avec le prototype complet. L'ambition, à terme, est de doter l'application principale de la capacité à ancrer ses réponses dans des sources de données privées, fournies par l'utilisateur.

*A propos de full_app_prototype :*

Ce projet se présente comme un logiciel de bureau conçu pour interagir avec des intelligences artificielles qui tournent localement grâce à Ollama.
Sa véritable particularité réside dans sa capacité à orchestrer des "équipes" d'agents IA pour résoudre des problèmes en plusieurs étapes. L'idée est d'aller au-delà d'une simple conversation. Quand une demande est trop complexe pour une seule réponse, un module intelligent nommé Maestro prend les choses en main. Ce dernier agit comme un chef de projet : il analyse la requête de l'utilisateur, la segmente en une série de missions distinctes et génère à la volée un schéma de travail complet. Ce schéma connecte différents agents spécialisés, chacun ayant un rôle précis, et définit comment les informations transitent de l'un à l'autre jusqu'à la résolution finale. Le système est même capable de corriger automatiquement ce plan s'il détecte des incohérences, comme un agent dont le travail ne serait pas utilisé.
Pour garantir une restitution claire, un dernier agent intervient pour synthétiser et mettre en forme l'ensemble des résultats produits, livrant ainsi un rapport final unifié et facile à lire. L'interface graphique offre également la possibilité de visualiser et de modifier ces schémas de travail sur un espace de type "canvas", de sauvegarder ses propres créations et bien sûr de choisir le modèle de langage que l'on souhaite utiliser.

*A propos de NebuAI_WebUI :*

Ce projet, qui est assez ancien, est le fruit d'un travail collaboratif et représente ma première expérience dans la création d'interfaces. C'est une application de discussion locale conçue pour dialoguer avec des modèles de langage, que ce soit via Ollama ou l'API d'OpenAI. Pour le côté technique, il repose sur Python et la bibliothèque Dash pour générer une interface web interactive.
L'intérêt principal est d'offrir un cadre de travail pour guider et approfondir le raisonnement de l'intelligence artificielle avant qu'elle ne fournisse sa réponse finale. Pour y parvenir, l'approche est plus structurée qu'un simple échange de questions-réponses. Plutôt que de simplement attendre une réponse directe à une question, l'utilisateur peut activer une ou plusieurs "fonctions de réflexion". Il s'agit de techniques de raisonnement prédéfinies, comme la "Chaîne de Pensée" ou le "Questionnement Socratique". Le programme demande alors au modèle d'appliquer ces méthodes en interne pour analyser la question sous différents angles.
Pour éviter que les extraits de code volumineux ou les tableaux ne polluent la conversation, ceux-ci sont automatiquement extraits et présentés sous forme de boutons cliquables. Un clic ouvre le contenu dans un visualiseur dédié, baptisé "Indy", où il est facile de le consulter et de le copier. L'interface permet également de charger un document PDF pour interroger son contenu (RAG), de basculer facilement entre les différents modèles de langage disponibles, et de visualiser en détail les étapes de raisonnement générées par les fonctions de réflexion dans un panneau latéral.

*A propos de only_maestro_prototype :*

Ce projet est un module de développement spécialisé, conçu pour être une future brique technologique de mon application principale. Il a été développé séparément afin de perfectionner une fonctionnalité centrale : la génération de réponses structurées et complexes par une intelligence artificielle.
Le principal objectif est de développer une approche méthodique de la génération de contenu. Plutôt que de simplement poser une question et d'attendre une réponse monolithique, ce module utilise un "Maestro" qui agit comme architecte de l'information. Le processus se déroule en deux temps : d'abord, l'IA est chargée de concevoir un plan de réponse détaillé, à la manière d'un sommaire, en décomposant la requête initiale en plusieurs parties et sous-parties logiques. Ensuite, ce plan est automatiquement transformé en un workflow multi-agents, où chaque agent se voit assigner la tâche de rédiger une section spécifique du plan.
Pour garantir la fiabilité de ce processus, le système intègre des mécanismes de robustesse, comme des tentatives multiples et une logique d'analyse avancée pour extraire et valider le plan généré, même si la sortie du modèle est imparfaite. Une attention particulière a été portée à la gestion des contenus techniques, avec notamment une prise en charge native du rendu des formules mathématiques grâce à l'intégration de LaTeX.
L'interface actuelle est volontairement minimaliste et entièrement dédiée à cette fonctionnalité. Elle permet de soumettre une demande, d'ajuster la complexité du plan attendu, et de visualiser en temps réel le travail de chaque agent, avant de voir le résultat final assemblé. L'objectif est d'intégrer ce moteur de génération de contenu avancé dans le prototype complet, afin d'y ajouter des capacités d'analyse et de rédaction bien plus poussées.
