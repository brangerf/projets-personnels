# projets-personnels

*A propos de chat_and_rag :*

Ce projet est une application de bureau qui permet de chatter avec des modèles de langage locaux via Ollama. Je l'ai construit en utilisant Python pour la logique principale et une interface utilisateur en HTML et JavaScript, le tout unifié dans une fenêtre grâce à pywebview.
La fonctionnalité principale est de pouvoir poser des questions sur un document personnel. Pour la recherche sémantique, l'approche est un peu plus élaborée. Plutôt que de chercher les mots exacts de la question, j'utilise d'abord le modèle de langage pour extraire les concepts clés et leurs variations. Ensuite, le programme recherche ces termes dans le document et identifie les zones où ils sont les plus pertinents et concentrés. Ces passages sont évalués selon plusieurs critères, notamment la diversité des concepts qu'ils contiennent et la proximité des termes entre eux. Pour éviter de présenter des informations redondantes, un filtre de similarité Jaccard est appliqué pour ne retenir que les extraits les plus uniques, qui formeront le contexte final de la réponse.
L'interface permet aussi de régler quelques paramètres du modèle, comme la température ou la taille du contexte, et de modifier le prompt système pour ajuster le comportement de l'assistant.

*A propos de full_app_prototype :*

Ce projet se présente comme un logiciel de bureau conçu pour interagir avec des intelligences artificielles qui tournent localement grâce à Ollama. Pour le développer, j'ai opté pour une architecture hybride : le moteur principal est en Python, tandis que l'interface est construite avec les technologies web standards (HTML, JavaScript), le tout encapsulé dans une fenêtre native par la librairie pywebview.
Sa véritable particularité réside dans sa capacité à orchestrer des "équipes" d'agents IA pour résoudre des problèmes en plusieurs étapes. L'idée est d'aller au-delà d'une simple conversation. Quand une demande est trop complexe pour une seule réponse, un module intelligent nommé Maestro prend les choses en main. Ce dernier agit comme un chef de projet : il analyse la requête de l'utilisateur, la segmente en une série de missions distinctes et génère à la volée un schéma de travail complet. Ce schéma connecte différents agents spécialisés, chacun ayant un rôle précis, et définit comment les informations transitent de l'un à l'autre jusqu'à la résolution finale. Le système est même capable de corriger automatiquement ce plan s'il détecte des incohérences, comme un agent dont le travail ne serait pas utilisé.
Pour garantir une restitution claire, un dernier agent intervient pour synthétiser et mettre en forme l'ensemble des résultats produits, livrant ainsi un rapport final unifié et facile à lire. L'interface graphique offre également la possibilité de visualiser et de modifier ces schémas de travail sur un espace de type "canvas", de sauvegarder ses propres créations et bien sûr de choisir le modèle de langage que l'on souhaite utiliser.

*A propos de NebuAI_WebUI :*

Ce projet, qui est assez ancien, est le fruit d'un travail collaboratif et représente ma première expérience dans la création d'interfaces. C'est une application de discussion locale conçue pour dialoguer avec des modèles de langage, que ce soit via Ollama ou l'API d'OpenAI. Pour le côté technique, il repose sur Python et la bibliothèque Dash pour générer une interface web interactive.
L'intérêt principal est d'offrir un cadre de travail pour guider et approfondir le raisonnement de l'intelligence artificielle avant qu'elle ne fournisse sa réponse finale. Pour y parvenir, l'approche est plus structurée qu'un simple échange de questions-réponses. Plutôt que de simplement attendre une réponse directe à une question, l'utilisateur peut activer une ou plusieurs "fonctions de réflexion". Il s'agit de techniques de raisonnement prédéfinies, comme la "Chaîne de Pensée" ou le "Questionnement Socratique". Le programme demande alors au modèle d'appliquer ces méthodes en interne pour analyser la question sous différents angles.
Pour éviter que les extraits de code volumineux ou les tableaux ne polluent la conversation, ceux-ci sont automatiquement extraits et présentés sous forme de boutons cliquables. Un clic ouvre le contenu dans un visualiseur dédié, baptisé "Indy", où il est facile de le consulter et de le copier. L'interface permet également de charger un document PDF pour interroger son contenu (RAG), de basculer facilement entre les différents modèles de langage disponibles, et de visualiser en détail les étapes de raisonnement générées par les fonctions de réflexion dans un panneau latéral.
